---
layout:     post
title:      SAR图像去噪论文笔记（二）ID-CNN
subtitle:   
date:       2020-11-29
author:     HSH
header-img: img/OIP.png
catalog: true
---

论文链接：[SAR Image Despeckling Using a Convolutional Neural Network](https://arxiv.org/pdf/1706.00552.pdf)

书接上回，SAR-CNN作为深度学习方法在SAR去噪最初的探索，取得了很好的成绩，当然对于它的不足之处，我们来看看新的ID-CNN有没有改进。

## 概述

论文先介绍了一下SAR图像噪声的性质：设干净图像为X，噪声为F，真实的有噪图像为Y，那么三者关系为

![](http://latex.codecogs.com/gif.latex?Y=FX)

且噪声F服从Gamma分布

* 不做log-exp的转换，直接估计乘性噪声

* 跳跃连接的除法结构
* 新的损失函数设计L2+TV LOSS

## 网络结构

![](https://i.bmp.ovh/imgs/2020/11/806a19932098032c.png)

作者提出像SAR-CNN的log-exp转换使得模型不是端到端的，于是在这个模型中不做同态转换而是直接估计噪声，用除法运算重建图像。

卷积层的设置：

![](https://i.bmp.ovh/imgs/2020/11/fcb2f4f43bd48cea.png)

##  损失函数

作者提出直接使用L2损失会使图像出现伪影（various artifacts），并提出新的损失函数TV LOSS:

![](http://latex.codecogs.com/gif.latex?L_{T V}= \sum_{w=1}^{W} \sum_{h=1}^{H} \sqrt{\left(\hat{X}^{w+1, h}-\hat{X}^{w, h}\right)^{2}+\left(\hat{X}^{w, h+1}-\hat{X}^{w, h}\right)^{2}})

与L2相结合得到最终的LOSS：

![](http://latex.codecogs.com/gif.latex?L=L_E+\lambda_{TV}L_{TV})

其中的lambda为需要提前设置的超参数。这样就能在保证细节的同时保持平滑。

## 实验

### 消融学习

![](https://i.bmp.ovh/imgs/2020/11/2b98fde4b5f5fadd.png)

### 合成数据

PSNR、SSIM和UQI(universal quality index)三个指标，比上一篇SAR-CNN提升很大。与只用L2损失函数的CNN表现好很多。主要得益于除法跳跃连接和损失函数的设计。

![](https://i.bmp.ovh/imgs/2020/11/f9b32271c4bbbe42.png)

### 真实数据

在ENL的指标上ID-CNN表现良好。

![](https://i.bmp.ovh/imgs/2020/11/f554b4f199764ecf.png)

从主观的视觉上分析，PPB和SAR-CNN存在伪影，基于滤波的PPB和BM3D边缘比较模糊。

### 速度

![](https://i.bmp.ovh/imgs/2020/11/4e56b5886062fca6.png)

## 总结

优点：

+ 在损失函数上简单的设计改善了去噪性能，通过消融学习有力地证明了设计的有效性
+ 放弃log-exp同态化处理，实现了端到端的结构

缺点：

+ CNN结构上的设计有点简单，可能还有改进空间